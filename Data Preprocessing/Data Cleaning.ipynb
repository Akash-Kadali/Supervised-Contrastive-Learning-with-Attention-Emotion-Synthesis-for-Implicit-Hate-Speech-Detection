{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b999f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kadal\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\kadal\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "C:\\Users\\kadal\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7724ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove URLs from text\n",
    "def remove_urls(vTEXT):\n",
    "    vTEXT = re.sub(r'(https|http)?:\\/\\/(\\w|\\.|\\-|\\/|\\?|\\=|\\&|\\%)*\\b', '', vTEXT, flags=re.MULTILINE)\n",
    "    vTEXT = re.sub(r'(www)(\\w|\\.|\\-|\\/|\\?|\\=|\\&|\\%)*\\b', '', vTEXT, flags=re.MULTILINE)\n",
    "    return vTEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c876b773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionaries for abbreviations and emojis\n",
    "# (same as provided in the original script)\n",
    "no_abbre =  {\n",
    "    \"ain't\": \"have not\",\n",
    "    \"aren't\": \"are not\",\n",
    "    \"can't\": \"cannot\",\n",
    "    \"couldn't\": \"could not\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"hadn't\": \"had not\",\n",
    "    \"hasn't\": \"has not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"he'd\": \"he would\",\n",
    "    \"he'll\": \"he will\",\n",
    "    \"he's\": \"he is\",\n",
    "    \"i'd\": \"I would\",\n",
    "    \"i'd\": \"I had\",\n",
    "    \"i'll\": \"I will\",\n",
    "    \"i'm\": \"I am\",\n",
    "    \"isn't\": \"is not\",\n",
    "    \"it's\": \"it is\",\n",
    "    \"it'll\": \"it will\",\n",
    "    \"i've\": \"I have\",\n",
    "    \"let's\": \"let us\",\n",
    "    \"mightn't\": \"might not\",\n",
    "    \"mustn't\": \"must not\",\n",
    "    \"shan't\": \"shall not\",\n",
    "    \"she'd\": \"she would\",\n",
    "    \"she'll\": \"she will\",\n",
    "    \"she's\": \"she is\",\n",
    "    \"shouldn't\": \"should not\",\n",
    "    \"that's\": \"that is\",\n",
    "    \"there's\": \"there is\",\n",
    "    \"they'd\": \"they would\",\n",
    "    \"they'll\": \"they will\",\n",
    "    \"they're\": \"they are\",\n",
    "    \"they've\": \"they have\",\n",
    "    \"we'd\": \"we would\",\n",
    "    \"we're\": \"we are\",\n",
    "    \"weren't\": \"were not\",\n",
    "    \"we've\": \"we have\",\n",
    "    \"what'll\": \"what will\",\n",
    "    \"what're\": \"what are\",\n",
    "    \"what's\": \"what is\",\n",
    "    \"what've\": \"what have\",\n",
    "    \"where's\": \"where is\",\n",
    "    \"who'd\": \"who would\",\n",
    "    \"who'll\": \"who will\",\n",
    "    \"who're\": \"who are\",\n",
    "    \"who's\": \"who is\",\n",
    "    \"who've\": \"who have\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"wouldn't\": \"would not\",\n",
    "    \"you'd\": \"you would\",\n",
    "    \"you'll\": \"you will\",\n",
    "    \"you're\": \"you are\",\n",
    "    \"you've\": \"you have\",\n",
    "    \"'re\": \" are\",\n",
    "    \"wasn't\": \"was not\",\n",
    "    \"we'll\": \" will\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"tryin'\": \"trying\",\n",
    "    \"ye\": \"you\",\n",
    "    \"stfu\": \"shut the fuck up\",\n",
    "    \"idubzz\": \"cancer\",\n",
    "    \"ho\": \"hoe\",\n",
    "    \"im\": \"i am\",\n",
    "    \"dm\": \"direct message\",\n",
    "    \"doesnt\": \"does not\",\n",
    "    \"its\": \"it is\",\n",
    "    \"lolol\": \"laugh out loud\",\n",
    "    \"lol\": \"laugh out loud\",\n",
    "    \"lil\": \"little\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3656a54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji = {\n",
    "    \"&lt;3\": \" good \",\n",
    "    \":d\": \" good \",\n",
    "    \":dd\": \" good \",\n",
    "    \":p\": \" good \",\n",
    "    \"8)\": \" good \",\n",
    "    \":-)\": \" good \",\n",
    "    \":)\": \" good \",\n",
    "    \";)\": \" good \",\n",
    "    \"(-:\": \" good \",\n",
    "    \"(:\": \" good \",\n",
    "    \"yay!\": \" good \",\n",
    "    \"yay\": \" good \",\n",
    "    \"yaay\": \" good \",\n",
    "    \"yaaay\": \" good \",\n",
    "    \"yaaaay\": \" good \",\n",
    "    \"yaaaaay\": \" good \",\n",
    "    \":/\": \" bad \",\n",
    "    \":&gt;\": \" sad \",\n",
    "    \":')\": \" sad \",\n",
    "    \":-(\": \" bad \",\n",
    "    \":(\": \" bad \",\n",
    "    \":s\": \" bad \",\n",
    "    \":-s\": \" bad \",\n",
    "    \"&lt;3\": \" heart \",\n",
    "    \":d\": \" smile \",\n",
    "    \":p\": \" smile \",\n",
    "    \":dd\": \" smile \",\n",
    "    \"8)\": \" smile \",\n",
    "    \":-)\": \" smile \",\n",
    "    \":)\": \" smile \",\n",
    "    \";)\": \" smile \",\n",
    "    \"(-:\": \" smile \",\n",
    "    \"(:\": \" smile \",\n",
    "    \":/\": \" worry \",\n",
    "    \":&gt;\": \" angry \",\n",
    "    \":')\": \" sad \",\n",
    "    \":-(\": \" sad \",\n",
    "    \":(\": \" sad \",\n",
    "    \":s\": \" sad \",\n",
    "    \":-s\": \" sad \",\n",
    "    r\"\\br\\b\": \"are\",\n",
    "    r\"\\bu\\b\": \"you\",\n",
    "    r\"\\bhaha\\b\": \"ha\",\n",
    "    r\"\\bhahaha\\b\": \"ha\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51f704f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of stop words\n",
    "# (same as provided in the original script)\n",
    "stop_words = [\n",
    "    'the', 'a', 'an', 'and', 'but', 'if', 'or', 'because', 'as', 'what',\n",
    "    'which', 'this', 'that', 'these', 'those', 'then', 'just', 'so', 'than',\n",
    "    'such', 'both', 'through', 'about', 'for', 'is', 'of', 'while', 'during',\n",
    "    'to'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce95094e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def substitute_repeats_fixed_len(text, nchars, ntimes=3):\n",
    "    return re.sub(r\"(\\S{{{}}})(\\1{{{},}})\".format(nchars, ntimes - 1), r\"\\1\",\n",
    "                  text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f80881e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def substitute_repeats(text, ntimes=3):\n",
    "    # Truncate consecutive repeats of short strings\n",
    "    for nchars in range(1, 20):\n",
    "        text = substitute_repeats_fixed_len(text, nchars, ntimes)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "945d3570",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(comment, remove_stopwords=True, remove_punctuations=False):\n",
    "    comment = remove_urls(comment.lower())\n",
    "    comment = re.sub(r\"\\t\", \" \", comment)\n",
    "    comment = re.sub(r\"\\r\\n\", \" . \", comment)\n",
    "    comment = re.sub(r\"\\r\", \" . \", comment)\n",
    "    comment = re.sub(r\"\\n\", \" . \", comment)\n",
    "    comment = re.sub(r\"\\\\n\\n\", \" . \", comment)\n",
    "    comment = re.sub(\"\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\", \"\", comment)\n",
    "    comment = re.sub(\"\\[\\[.*\\]\", \"\", comment)\n",
    "    comment = re.sub(r\"\\'ve\", \" have \", comment)\n",
    "\n",
    "    comment = re.sub(r\"\\'d\", \" would \", comment)\n",
    "    comment = re.sub(r\"\\'ll\", \" will \", comment)\n",
    "    comment = re.sub(r\"ca not\", \"cannot\", comment)\n",
    "    comment = re.sub(r\"you ' re\", \"you are\", comment)\n",
    "    comment = re.sub(r\"wtf\", \"what the fuck\", comment)\n",
    "    comment = re.sub(r\"i ' m\", \"I am\", comment)\n",
    "    comment = re.sub(r\"I\", \"one\", comment)\n",
    "    comment = re.sub(r\"II\", \"two\", comment)\n",
    "    comment = re.sub(r\"III\", \"three\", comment)\n",
    "    comment = re.sub(r\"mothjer\", \"mother\", comment)\n",
    "    comment = re.sub(r\"nazi\", \"nazy\", comment)\n",
    "    comment = re.sub(r\"withought\", \"with out\", comment)\n",
    "    comment = substitute_repeats(comment)\n",
    "    s = comment\n",
    "\n",
    "    s = s.replace('&', '')\n",
    "    s = s.replace('@', '')\n",
    "    s = s.replace('0', '')\n",
    "    s = s.replace('1', '')\n",
    "    s = s.replace('2', '')\n",
    "    s = s.replace('3', '')\n",
    "    s = s.replace('4', '')\n",
    "    s = s.replace('5', '')\n",
    "    s = s.replace('6', '')\n",
    "    s = s.replace('7', '')\n",
    "    s = s.replace('8', '')\n",
    "    s = s.replace('9', '')\n",
    "\n",
    "    comment = s\n",
    "\n",
    "    words = tokenizer.tokenize(comment)\n",
    "    words = [no_abbre[word] if word in no_abbre else word for word in words]\n",
    "    words = [emoji[word] if word in emoji else word for word in words]\n",
    "    if remove_stopwords:\n",
    "        words = [w for w in words if not w in stop_words]\n",
    "\n",
    "    sent = \" \".join(words)\n",
    "    # Remove some special characters, or noise charater, but do not remove all!!\n",
    "    if remove_punctuations:\n",
    "        sent = re.sub(r'([\\'\\\"\\/\\-\\_\\--\\_])', ' ', sent)\n",
    "    else:\n",
    "        sent = re.sub(r'([\\'\\\"\\/\\-\\_\\-\\_\\(\\)\\{\\}])', ' ', sent)\n",
    "    clean_sent = re.sub(r'([\\;\\|•«\\n])', ' ', sent)\n",
    "    clean_sent = re.sub(r\"n't\", \" not \", clean_sent)\n",
    "\n",
    "    FLAG_remove_non_ascii = True\n",
    "    if FLAG_remove_non_ascii:\n",
    "        return clean_sent.encode(\"ascii\", errors=\"ignore\").decode().strip()\n",
    "    else:\n",
    "        return clean_sent.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3ef2d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "tokenizer = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e512f592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>in islam , rape , murder , theft , war are pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>despite fact there are many eminently disabled...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>gambling obviously favorite pastime jews .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>historically , suicide bombings have been carr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>i guess it is sort backhand compliment anti wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259399</th>\n",
       "      <td>2</td>\n",
       "      <td>courageous italian cop who arrested illegal im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259400</th>\n",
       "      <td>2</td>\n",
       "      <td>you might notice there are few black executive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259401</th>\n",
       "      <td>0</td>\n",
       "      <td>mimimatthews.com . campaign = buffer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259402</th>\n",
       "      <td>2</td>\n",
       "      <td>clearly , naturalization act stated whites cou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259403</th>\n",
       "      <td>2</td>\n",
       "      <td>having caravan park home perfect me .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>259404 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        label                                       cleaned_text\n",
       "0           1  in islam , rape , murder , theft , war are pro...\n",
       "1           2  despite fact there are many eminently disabled...\n",
       "2           2         gambling obviously favorite pastime jews .\n",
       "3           2  historically , suicide bombings have been carr...\n",
       "4           2  i guess it is sort backhand compliment anti wh...\n",
       "...       ...                                                ...\n",
       "259399      2  courageous italian cop who arrested illegal im...\n",
       "259400      2  you might notice there are few black executive...\n",
       "259401      0               mimimatthews.com . campaign = buffer\n",
       "259402      2  clearly , naturalization act stated whites cou...\n",
       "259403      2              having caravan park home perfect me .\n",
       "\n",
       "[259404 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('cleaned_train_new_final.csv')\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8af33d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('cleaned_train_new_final.csv')\n",
    "\n",
    "# Create a new column to store the cleaned text\n",
    "df_train['cleaned_text_new'] = \"\"\n",
    "\n",
    "for index, row in df_train.iterrows():\n",
    "    text = row['cleaned_text']\n",
    "    if isinstance(text, str):  # Check if the 'text' is a string\n",
    "        cleaned_text = clean(text)\n",
    "        df_train.at[index, 'cleaned_text_new'] = cleaned_text\n",
    "\n",
    "# Save the cleaned DataFrame to a new CSV file\n",
    "# Replace 'cleaned_train.csv' with the desired name for the output file\n",
    "df_train.to_csv('clean_train_new.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30580c02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>cleaned_text_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>in islam , rape , murder , theft , war are pro...</td>\n",
       "      <td>in islam , rape , murder , theft , war are pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>despite fact there are many eminently disabled...</td>\n",
       "      <td>despite fact there are many eminently disabled...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>gambling obviously favorite pastime jews .</td>\n",
       "      <td>gambling obviously favorite pastime jews .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>historically , suicide bombings have been carr...</td>\n",
       "      <td>historically , suicide bombings have been carr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>i guess it is sort backhand compliment anti wh...</td>\n",
       "      <td>i guess it sort backhand compliment anti white...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259399</th>\n",
       "      <td>2</td>\n",
       "      <td>courageous italian cop who arrested illegal im...</td>\n",
       "      <td>courageous italian cop who arrested illegal im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259400</th>\n",
       "      <td>2</td>\n",
       "      <td>you might notice there are few black executive...</td>\n",
       "      <td>you might notice there are few black executive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259401</th>\n",
       "      <td>0</td>\n",
       "      <td>mimimatthews.com . campaign = buffer</td>\n",
       "      <td>mimimatthews.com . campaign = buffer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259402</th>\n",
       "      <td>2</td>\n",
       "      <td>clearly , naturalization act stated whites cou...</td>\n",
       "      <td>clearly , naturalization act stated whites cou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259403</th>\n",
       "      <td>2</td>\n",
       "      <td>having caravan park home perfect me .</td>\n",
       "      <td>having caravan park home perfect me .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>259404 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        label                                       cleaned_text  \\\n",
       "0           1  in islam , rape , murder , theft , war are pro...   \n",
       "1           2  despite fact there are many eminently disabled...   \n",
       "2           2         gambling obviously favorite pastime jews .   \n",
       "3           2  historically , suicide bombings have been carr...   \n",
       "4           2  i guess it is sort backhand compliment anti wh...   \n",
       "...       ...                                                ...   \n",
       "259399      2  courageous italian cop who arrested illegal im...   \n",
       "259400      2  you might notice there are few black executive...   \n",
       "259401      0               mimimatthews.com . campaign = buffer   \n",
       "259402      2  clearly , naturalization act stated whites cou...   \n",
       "259403      2              having caravan park home perfect me .   \n",
       "\n",
       "                                         cleaned_text_new  \n",
       "0       in islam , rape , murder , theft , war are pro...  \n",
       "1       despite fact there are many eminently disabled...  \n",
       "2              gambling obviously favorite pastime jews .  \n",
       "3       historically , suicide bombings have been carr...  \n",
       "4       i guess it sort backhand compliment anti white...  \n",
       "...                                                   ...  \n",
       "259399  courageous italian cop who arrested illegal im...  \n",
       "259400  you might notice there are few black executive...  \n",
       "259401               mimimatthews.com . campaign = buffer  \n",
       "259402  clearly , naturalization act stated whites cou...  \n",
       "259403              having caravan park home perfect me .  \n",
       "\n",
       "[259404 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef716058",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('BERT + BT/Subtle/train_bt.csv')\n",
    "\n",
    "# Create a new column to store the cleaned text\n",
    "df_train['cleaned_text'] = \"\"\n",
    "\n",
    "for index, row in df_train.iterrows():\n",
    "    text = row['text']\n",
    "    if isinstance(text, str):  # Check if the 'text' is a string\n",
    "        cleaned_text = clean(text)\n",
    "        df_train.at[index, 'cleaned_text'] = cleaned_text\n",
    "\n",
    "# Save the cleaned DataFrame to a new CSV file\n",
    "# Replace 'cleaned_train.csv' with the desired name for the output file\n",
    "df_train.to_csv('BERT + BT/Subtle/cleaned_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4771ae3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('BERT + RNE/Implicit/train_rne.csv')\n",
    "\n",
    "# Create a new column to store the cleaned text\n",
    "df_train['cleaned_text'] = \"\"\n",
    "\n",
    "for index, row in df_train.iterrows():\n",
    "    text = row['text']\n",
    "    if isinstance(text, str):  # Check if the 'text' is a string\n",
    "        cleaned_text = clean(text)\n",
    "        df_train.at[index, 'cleaned_text'] = cleaned_text\n",
    "\n",
    "# Save the cleaned DataFrame to a new CSV file\n",
    "# Replace 'cleaned_train.csv' with the desired name for the output file\n",
    "df_train.to_csv('BERT + RNE/Implicit/cleaned_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b41be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('BERT + RNE/Subtle/train_rne.csv')\n",
    "\n",
    "# Create a new column to store the cleaned text\n",
    "df_train['cleaned_text'] = \"\"\n",
    "\n",
    "for index, row in df_train.iterrows():\n",
    "    text = row['text']\n",
    "    if isinstance(text, str):  # Check if the 'text' is a string\n",
    "        cleaned_text = clean(text)\n",
    "        df_train.at[index, 'cleaned_text'] = cleaned_text\n",
    "\n",
    "# Save the cleaned DataFrame to a new CSV file\n",
    "# Replace 'cleaned_train.csv' with the desired name for the output file\n",
    "df_train.to_csv('BERT + RNE/Subtle/cleaned_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e940195",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('DeBERTa + BT/Implicit/train_bt.csv')\n",
    "\n",
    "# Create a new column to store the cleaned text\n",
    "df_train['cleaned_text'] = \"\"\n",
    "\n",
    "for index, row in df_train.iterrows():\n",
    "    text = row['text']\n",
    "    if isinstance(text, str):  # Check if the 'text' is a string\n",
    "        cleaned_text = clean(text)\n",
    "        df_train.at[index, 'cleaned_text'] = cleaned_text\n",
    "\n",
    "# Save the cleaned DataFrame to a new CSV file\n",
    "# Replace 'cleaned_train.csv' with the desired name for the output file\n",
    "df_train.to_csv('DeBERTa + BT/Implicit/cleaned_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc211c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('DeBERTa + BT/Subtle/train_bt.csv')\n",
    "\n",
    "# Create a new column to store the cleaned text\n",
    "df_train['cleaned_text'] = \"\"\n",
    "\n",
    "for index, row in df_train.iterrows():\n",
    "    text = row['text']\n",
    "    if isinstance(text, str):  # Check if the 'text' is a string\n",
    "        cleaned_text = clean(text)\n",
    "        df_train.at[index, 'cleaned_text'] = cleaned_text\n",
    "\n",
    "# Save the cleaned DataFrame to a new CSV file\n",
    "# Replace 'cleaned_train.csv' with the desired name for the output file\n",
    "df_train.to_csv('DeBERTa + BT/Subtle/cleaned_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd8081a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('DeBERTa + RI/Implicit/train_ri.csv')\n",
    "\n",
    "# Create a new column to store the cleaned text\n",
    "df_train['cleaned_text'] = \"\"\n",
    "\n",
    "for index, row in df_train.iterrows():\n",
    "    text = row['text']\n",
    "    if isinstance(text, str):  # Check if the 'text' is a string\n",
    "        cleaned_text = clean(text)\n",
    "        df_train.at[index, 'cleaned_text'] = cleaned_text\n",
    "\n",
    "# Save the cleaned DataFrame to a new CSV file\n",
    "# Replace 'cleaned_train.csv' with the desired name for the output file\n",
    "df_train.to_csv('DeBERTa + RI/Implicit/cleaned_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70100edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('DeBERTa + RI/Subtle/train_ri.csv')\n",
    "\n",
    "# Create a new column to store the cleaned text\n",
    "df_train['cleaned_text'] = \"\"\n",
    "\n",
    "for index, row in df_train.iterrows():\n",
    "    text = row['text']\n",
    "    if isinstance(text, str):  # Check if the 'text' is a string\n",
    "        cleaned_text = clean(text)\n",
    "        df_train.at[index, 'cleaned_text'] = cleaned_text\n",
    "\n",
    "# Save the cleaned DataFrame to a new CSV file\n",
    "# Replace 'cleaned_train.csv' with the desired name for the output file\n",
    "df_train.to_csv('DeBERTa + RI/Subtle/cleaned_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144cb5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('HateBERT + ALL/Implicit/train_all.csv')\n",
    "\n",
    "# Create a new column to store the cleaned text\n",
    "df_train['cleaned_text'] = \"\"\n",
    "\n",
    "for index, row in df_train.iterrows():\n",
    "    text = row['text']\n",
    "    if isinstance(text, str):  # Check if the 'text' is a string\n",
    "        cleaned_text = clean(text)\n",
    "        df_train.at[index, 'cleaned_text'] = cleaned_text\n",
    "\n",
    "# Save the cleaned DataFrame to a new CSV file\n",
    "# Replace 'cleaned_train.csv' with the desired name for the output file\n",
    "df_train.to_csv('HateBERT + ALL/Implicit/cleaned_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9268001d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('HateBERT + ALL/Subtle/train_all.csv')\n",
    "\n",
    "# Create a new column to store the cleaned text\n",
    "df_train['cleaned_text'] = \"\"\n",
    "\n",
    "for index, row in df_train.iterrows():\n",
    "    text = row['text']\n",
    "    if isinstance(text, str):  # Check if the 'text' is a string\n",
    "        cleaned_text = clean(text)\n",
    "        df_train.at[index, 'cleaned_text'] = cleaned_text\n",
    "\n",
    "# Save the cleaned DataFrame to a new CSV file\n",
    "# Replace 'cleaned_train.csv' with the desired name for the output file\n",
    "df_train.to_csv('HateBERT + ALL/Subtle/cleaned_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333d9355",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('HateBERT + GM/Implicit/train_gm.csv')\n",
    "\n",
    "# Create a new column to store the cleaned text\n",
    "df_train['cleaned_text'] = \"\"\n",
    "\n",
    "for index, row in df_train.iterrows():\n",
    "    text = row['text']\n",
    "    if isinstance(text, str):  # Check if the 'text' is a string\n",
    "        cleaned_text = clean(text)\n",
    "        df_train.at[index, 'cleaned_text'] = cleaned_text\n",
    "\n",
    "# Save the cleaned DataFrame to a new CSV file\n",
    "# Replace 'cleaned_train.csv' with the desired name for the output file\n",
    "df_train.to_csv('HateBERT + GM/Implicit/cleaned_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe40e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('HateBERT + GM/Subtle/train_gm.csv')\n",
    "\n",
    "# Create a new column to store the cleaned text\n",
    "df_train['cleaned_text'] = \"\"\n",
    "\n",
    "for index, row in df_train.iterrows():\n",
    "    text = row['text']\n",
    "    if isinstance(text, str):  # Check if the 'text' is a string\n",
    "        cleaned_text = clean(text)\n",
    "        df_train.at[index, 'cleaned_text'] = cleaned_text\n",
    "\n",
    "# Save the cleaned DataFrame to a new CSV file\n",
    "# Replace 'cleaned_train.csv' with the desired name for the output file\n",
    "df_train.to_csv('HateBERT + GM/Subtle/cleaned_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416aa4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('HateBERT + GM + GM Revised/Implicit/train_gmr.csv')\n",
    "\n",
    "# Create a new column to store the cleaned text\n",
    "df_train['cleaned_text'] = \"\"\n",
    "\n",
    "for index, row in df_train.iterrows():\n",
    "    text = row['text']\n",
    "    if isinstance(text, str):  # Check if the 'text' is a string\n",
    "        cleaned_text = clean(text)\n",
    "        df_train.at[index, 'cleaned_text'] = cleaned_text\n",
    "\n",
    "# Save the cleaned DataFrame to a new CSV file\n",
    "# Replace 'cleaned_train.csv' with the desired name for the output file\n",
    "df_train.to_csv('HateBERT + GM + GM Revised/Implicit/cleaned_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a66b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('HateBERT + GM + GM Revised/Subtle/train_gmr.csv')\n",
    "\n",
    "# Create a new column to store the cleaned text\n",
    "df_train['cleaned_text'] = \"\"\n",
    "\n",
    "for index, row in df_train.iterrows():\n",
    "    text = row['text']\n",
    "    if isinstance(text, str):  # Check if the 'text' is a string\n",
    "        cleaned_text = clean(text)\n",
    "        df_train.at[index, 'cleaned_text'] = cleaned_text\n",
    "\n",
    "# Save the cleaned DataFrame to a new CSV file\n",
    "# Replace 'cleaned_train.csv' with the desired name for the output file\n",
    "df_train.to_csv('HateBERT + GM + GM Revised/Subtle/cleaned_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db03ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('USE + SVM + BT/Implicit/train_bt.csv')\n",
    "\n",
    "# Create a new column to store the cleaned text\n",
    "df_train['cleaned_text'] = \"\"\n",
    "\n",
    "for index, row in df_train.iterrows():\n",
    "    text = row['text']\n",
    "    if isinstance(text, str):  # Check if the 'text' is a string\n",
    "        cleaned_text = clean(text)\n",
    "        df_train.at[index, 'cleaned_text'] = cleaned_text\n",
    "\n",
    "# Save the cleaned DataFrame to a new CSV file\n",
    "# Replace 'cleaned_train.csv' with the desired name for the output file\n",
    "df_train.to_csv('USE + SVM + BT/Implicit/cleaned_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a19704",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('USE + SVM + BT/Subtle/train_bt.csv')\n",
    "\n",
    "# Create a new column to store the cleaned text\n",
    "df_train['cleaned_text'] = \"\"\n",
    "\n",
    "for index, row in df_train.iterrows():\n",
    "    text = row['text']\n",
    "    if isinstance(text, str):  # Check if the 'text' is a string\n",
    "        cleaned_text = clean(text)\n",
    "        df_train.at[index, 'cleaned_text'] = cleaned_text\n",
    "\n",
    "# Save the cleaned DataFrame to a new CSV file\n",
    "# Replace 'cleaned_train.csv' with the desired name for the output file\n",
    "df_train.to_csv('USE + SVM + BT/Subtle/cleaned_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ed81f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('Implicit/implicit_test.csv')\n",
    "\n",
    "# Create a new column to store the cleaned text\n",
    "df_train['cleaned_text'] = \"\"\n",
    "\n",
    "for index, row in df_train.iterrows():\n",
    "    text = row['text']\n",
    "    if isinstance(text, str):  # Check if the 'text' is a string\n",
    "        cleaned_text = clean(text)\n",
    "        df_train.at[index, 'cleaned_text'] = cleaned_text\n",
    "\n",
    "# Save the cleaned DataFrame to a new CSV file\n",
    "# Replace 'cleaned_train.csv' with the desired name for the output file\n",
    "df_train.to_csv('Implicit/implicit_cleaned_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22307b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('Implicit/implicit_dev.csv')\n",
    "\n",
    "# Create a new column to store the cleaned text\n",
    "df_train['cleaned_text'] = \"\"\n",
    "\n",
    "for index, row in df_train.iterrows():\n",
    "    text = row['text']\n",
    "    if isinstance(text, str):  # Check if the 'text' is a string\n",
    "        cleaned_text = clean(text)\n",
    "        df_train.at[index, 'cleaned_text'] = cleaned_text\n",
    "\n",
    "# Save the cleaned DataFrame to a new CSV file\n",
    "# Replace 'cleaned_train.csv' with the desired name for the output file\n",
    "df_train.to_csv('Implicit/implicit_cleaned_dev.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee341df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('Subtle/subtle_test.csv')\n",
    "\n",
    "# Create a new column to store the cleaned text\n",
    "df_train['cleaned_text'] = \"\"\n",
    "\n",
    "for index, row in df_train.iterrows():\n",
    "    text = row['text']\n",
    "    if isinstance(text, str):  # Check if the 'text' is a string\n",
    "        cleaned_text = clean(text)\n",
    "        df_train.at[index, 'cleaned_text'] = cleaned_text\n",
    "\n",
    "# Save the cleaned DataFrame to a new CSV file\n",
    "# Replace 'cleaned_train.csv' with the desired name for the output file\n",
    "df_train.to_csv('Subtle/subtle_cleaned_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3376e0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('Subtle/subtle_dev.csv')\n",
    "\n",
    "# Create a new column to store the cleaned text\n",
    "df_train['cleaned_text'] = \"\"\n",
    "\n",
    "for index, row in df_train.iterrows():\n",
    "    text = row['text']\n",
    "    if isinstance(text, str):  # Check if the 'text' is a string\n",
    "        cleaned_text = clean(text)\n",
    "        df_train.at[index, 'cleaned_text'] = cleaned_text\n",
    "\n",
    "# Save the cleaned DataFrame to a new CSV file\n",
    "# Replace 'cleaned_train.csv' with the desired name for the output file\n",
    "df_train.to_csv('Subtle/subtle_cleaned_dev.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bb79f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
